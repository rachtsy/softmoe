local variable 'y' referenced before assignmentlocal variable 'y' referenced before assignmentlocal variable 'y' referenced before assignmentlocal variable 'y' referenced before assignmentinvalid load key, '{'.invalid load key, '{'.invalid load key, '{'.invalid load key, '{'.local variable 's' referenced before assignmentlocal variable 's' referenced before assignmentlocal variable 's' referenced before assignmentlocal variable 's' referenced before assignmentlocal variable 'l' referenced before assignmentlocal variable 'l' referenced before assignmentlocal variable 'l' referenced before assignmentlocal variable 'l' referenced before assignmentCUDA out of memory. Tried to allocate 148.00 MiB. GPU 1 has a total capacity of 39.39 GiB of which 11.94 MiB is free. Process 3094650 has 39.36 GiB memory in use. Of the allocated memory 37.47 GiB is allocated by PyTorch, and 259.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFCUDA out of memory. Tried to allocate 148.00 MiB. GPU 3 has a total capacity of 39.39 GiB of which 75.94 MiB is free. Process 3094652 has 39.30 GiB memory in use. Of the allocated memory 37.47 GiB is allocated by PyTorch, and 339.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFCUDA out of memory. Tried to allocate 148.00 MiB. GPU 2 has a total capacity of 39.39 GiB of which 107.94 MiB is free. Process 3094651 has 39.27 GiB memory in use. Of the allocated memory 37.33 GiB is allocated by PyTorch, and 311.90 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONFCUDA out of memory. Tried to allocate 148.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 75.94 MiB is free. Process 3094649 has 39.30 GiB memory in use. Of the allocated memory 37.47 GiB is allocated by PyTorch, and 339.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF